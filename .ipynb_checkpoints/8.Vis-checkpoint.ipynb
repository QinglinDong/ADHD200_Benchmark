{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/cache_mixin.py:232: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if (memory.cachedir is None and memory_level is not None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import scoreatpercentile\n",
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "from pylab import figure\n",
    "import os\n",
    "\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask_img, standardize=True)\n",
    "masker.fit()\n",
    "\n",
    "def flip(row):\n",
    "    if np.sum(row > 0) < np.sum(row < 0):\n",
    "        row *= -1\n",
    "    return row\n",
    "        \n",
    "import statistics\n",
    "# components_img1=stats.zscore(components_img1,axis=0)\n",
    "# components_img2=stats.zscore(components_img2,axis=0)\n",
    "# components_img3=stats.zscore(components_img3,axis=0)\n",
    "def thresholding(array):    \n",
    "    thr=[]\n",
    "    array1=array\n",
    "    \n",
    "    for idx,row in enumerate(array):\n",
    "        row=flip(row)  \n",
    "        row[row < 0] = 0\n",
    "        T=np.amax(row)*0.3\n",
    "        row[np.abs(row) < T] = 0\n",
    "        \n",
    "#         T=scoreatpercentile(np.abs(row),P)\n",
    "#         T=2.3                \n",
    "#         T=max(row)*0.2\n",
    "        \n",
    "        row=row/np.std(row)        \n",
    "        array1[idx,:]=row\n",
    "    return array1\n",
    "\n",
    "def save_maps(components_img,dir):        \n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    components_img = masker.inverse_transform(components_img)\n",
    "    for i, cur_img in enumerate(iter_img(components_img)):\n",
    "        outname=dir+str(i+1)+'.png'\n",
    "        plot_stat_map(cur_img, display_mode=\"z\", black_bg=True,cut_coords=1,annotate=False,\n",
    "                     colorbar=False,output_file=outname)\n",
    "        \n",
    "#         if i==5:\n",
    "#             break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis(task):\n",
    "    W1=np.load('/home/uga_qinglin/Documents/ADHD_DL/ADHD200_VAE_diction.npy')\n",
    "\n",
    "\n",
    "    components_img1=W1\n",
    "\n",
    "\n",
    "    components_img1=np.transpose(components_img1)\n",
    "\n",
    "    \n",
    "    components_img1=thresholding(components_img1)    \n",
    "\n",
    "\n",
    "    save_maps(components_img1,dir='/home/uga_qinglin/Documents/ADHD_DL/VAEmaps/')        \n",
    "    \n",
    "#     np.save('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy',components_img1)\n",
    "#     np.save('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map2.npy',components_img2)\n",
    "#     np.save('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map3.npy',components_img3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "Parallel(n_jobs=7)(delayed(vis)(task) for task in tasks)\n",
    "# vis('EMOTION')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
