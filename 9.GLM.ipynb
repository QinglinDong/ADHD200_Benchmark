{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/GAMBLING/IC1_high.nii.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-8596760115fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0msave_maps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaps_GLM\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-170-8596760115fa>\u001b[0m in \u001b[0;36msave_maps\u001b[0;34m(components_img, dir)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moutname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         plot_stat_map(cur_img, display_mode=\"z\", black_bg=True,cut_coords=10,\n\u001b[0;32m---> 37\u001b[0;31m                      colorbar=True,output_file=outname,title=\"Cope %d\" % int(i+1))\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EMOTION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'GAMBLING'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'LANGUAGE'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'MOTOR'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'RELATIONAL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SOCIAL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'WM'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36mplot_stat_map\u001b[0;34m(stat_map_img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, cmap, symmetric_cbar, dim, vmax, resampling_interpolation, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0mbg_vmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_vmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbg_vmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_vmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mcolorbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_vmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbar_vmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_vmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcbar_vmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m         resampling_interpolation=resampling_interpolation, **kwargs)\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36m_plot_img_with_bg\u001b[0;34m(img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, vmin, vmax, bg_vmin, bg_vmax, interpolation, display_factory, cbar_vmin, cbar_vmax, brain_color, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m         display.add_overlay(bg_img,\n\u001b[1;32m    181\u001b[0m                             \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_vmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbg_vmax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                             cmap=plt.cm.gray, interpolation=interpolation)\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/plotting/displays.py\u001b[0m in \u001b[0;36madd_overlay\u001b[0;34m(self, img, threshold, colorbar, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;31m# with plot_stat_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'interpolation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imshow'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# `ims` can be empty in some corner cases, look at test_img_plotting.test_outlier_cut_coords.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/plotting/displays.py\u001b[0m in \u001b[0;36m_map_show\u001b[0;34m(self, img, type, resampling_interpolation, threshold, **kwargs)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mnot_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mxmin_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymin_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymax_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmin_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzmax_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                 \u001b[0mget_mask_bounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_img_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnot_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mdata_2d_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/image/resampling.py\u001b[0m in \u001b[0;36mget_mask_bounds\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \"\"\"\n\u001b[0;32m--> 208\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_niimg_3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_conversions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0maffine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg_3d\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mIts\u001b[0m \u001b[0mapplication\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0midempotent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m                         + short_repr(niimg))\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_target_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manat_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0manat_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_fill_holes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manat_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_affine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manat_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1634.4x165.6 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "from nilearn import image\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "mask_img = load_mni152_brain_mask()\n",
    "masker = NiftiMasker(mask_img=mask_img,standardize=True)\n",
    "masker.fit()\n",
    "\n",
    "def flip(row):\n",
    "    if np.sum(row > 0) < np.sum(row < 0):\n",
    "        row *= -1\n",
    "        \n",
    "def load_maps(file):\n",
    "    print(file)\n",
    "    GLM=image.load_img(file)\n",
    "    maps_GLM=masker.transform(GLM)\n",
    "#     for row in maps_GLM:\n",
    "#         flip(row)\n",
    "    maps_GLM[maps_GLM<0]=0\n",
    "    return maps_GLM\n",
    "\n",
    "# plot GLM map\n",
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "from pylab import figure\n",
    "import os\n",
    "\n",
    "def save_maps(components_img,dir):        \n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    \n",
    "    for i, cur_img in enumerate(iter_img(components_img)):\n",
    "        outname=dir+str(i)+'.png'\n",
    "        plot_stat_map(cur_img, display_mode=\"z\", black_bg=True,cut_coords=10,\n",
    "                     colorbar=True,output_file=outname,title=\"Cope %d\" % int(i+1))\n",
    "\n",
    "tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "for task in tasks:\n",
    "    file='/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz'\n",
    "    maps_GLM=load_maps(file)\n",
    "    maps_GLM = masker.inverse_transform(maps_GLM)\n",
    "    dir='/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_GLM/'\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "    save_maps(maps_GLM,dir)        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "def MapOverlap( a, b):\n",
    "    Intersect = np.logical_and(a, b)\n",
    "    Union=np.logical_or(a, b)\n",
    "    return np.count_nonzero(Intersect)/np.count_nonzero(Union)\n",
    "def MapOverlap2( GLM, b):\n",
    "    Intersect = np.logical_and(GLM, b)\n",
    "    Union=np.logical_or(GLM, b)\n",
    "    if np.count_nonzero(Union)   ==0:\n",
    "        U=0\n",
    "    else:\n",
    "        U=np.count_nonzero(GLM)/np.count_nonzero(Union)   \n",
    "    return np.count_nonzero(Intersect)/np.count_nonzero(GLM)-U\n",
    "def MapHierach( a, b):\n",
    "    I = np.count_nonzero(np.logical_and(a, b))\n",
    "    A=np.count_nonzero(a)\n",
    "    B=np.count_nonzero(b)\n",
    "    return I/min([A,B])\n",
    "def Euclid(a,b):\n",
    "    a = np.where(a > 10e-6, 1, 0)\n",
    "    b = np.where(b > 10e-6, 1, 0)\n",
    "    np.count_nonzero(a-b)\n",
    "from scipy.stats import entropy\n",
    "def KL(a,b):\n",
    "    return (entropy(a,b)+entropy(b,a))/2\n",
    "from sklearn import metrics\n",
    "def LayerOverlap(A,B):\n",
    "    D=[]\n",
    "    for i,a in enumerate(A):\n",
    "        D.append([])\n",
    "        \n",
    "        for j,b in enumerate(B):\n",
    "#             score=metrics.mutual_info_score(a,b)\n",
    "            score=MapHierach(a,b)\n",
    "#             score=KL(a,b)\n",
    "#             score = Euclid(a,b)\n",
    "            D[i].append(score)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot all Overlap\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# def plot(D,file):\n",
    "#     plt.ylim(1, 7)\n",
    "#     plt.figure(figsize=(5,2))\n",
    "#     sns_plot=sns.heatmap(D,cmap=\"Reds\",vmax=1)\n",
    "#     plt.savefig(file, bbox_inches='tight')\n",
    "  \n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "# def run(task):\n",
    "#     map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "#     map2=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map2.npy')\n",
    "#     map3=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map3.npy')\n",
    "#     maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "#     D1=LayerOverlap(maps_GLM,map1)\n",
    "#     D2=LayerOverlap(maps_GLM,map2)\n",
    "#     D3=LayerOverlap(maps_GLM,map3)\n",
    "#     plot(D1,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D1.png')\n",
    "#     plot(D2,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D2.png')\n",
    "#     plot(D3,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D3.png')\n",
    "# from joblib import Parallel, delayed\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "# Parallel(n_jobs=7)(delayed(run)(task) for task in tasks)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
      "88 18 71\n",
      "88 88 8\n",
      "88 54 71\n",
      "88 80 89\n",
      "88 76 89\n",
      "88 88 89\n"
     ]
    }
   ],
   "source": [
    "# best match of 7 tasks\n",
    "import operator\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "def match(task):\n",
    "    map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "    map2=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map2.npy')\n",
    "    map3=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map3.npy')\n",
    "    maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "\n",
    "    D1=LayerOverlap(maps_GLM,map1)\n",
    "    D2=LayerOverlap(maps_GLM,map2)\n",
    "    D3=LayerOverlap(maps_GLM,map3)\n",
    "\n",
    "    src='/home/share/TmpData/Qinglin/HCP_Group_DBN/Maps_ortho/'\n",
    "    dst='/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_match/'\n",
    "    shutil.rmtree(dst) \n",
    "    if not os.path.exists(dst):\n",
    "            os.makedirs(dst)\n",
    "    \n",
    "    copyfile('/home/share/TmpData/Qinglin/HCP_4mm/100206/MNINonLinear/Results/tfMRI_'+task+'_LR/tfMRI_'+task+'_LR_hp200_s4.feat/design.png', dst+'design.png')\n",
    "    for t in list(range(0,len(maps_GLM))):\n",
    "#     for t in list(range(0,6)):\n",
    "        index1, value = max(enumerate(D1[t]), key=operator.itemgetter(1))\n",
    "        index2, value = max(enumerate(D2[t]), key=operator.itemgetter(1))\n",
    "        index3, value = max(enumerate(D3[t]), key=operator.itemgetter(1))\n",
    "        print(index1,index2,index3)        \n",
    "        copyfile(src+task+'_W1/'+str(index1+1)+'.png', dst+str(t)+'_W1_'+str(index1+1)+'.png')\n",
    "        copyfile(src+task+'_W2/'+str(index2+1)+'.png', dst+str(t)+'_W2_'+str(index1+1)+'.png')\n",
    "        copyfile(src+task+'_W3/'+str(index3+1)+'.png', dst+str(t)+'_W3_'+str(index1+1)+'.png')\n",
    "        \n",
    "        copyfile('/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/EMOTION_GLM/'+str(t)+'.png', dst+str(t)+'.png')\n",
    "        \n",
    "match('EMOTION')        \n",
    "# from joblib import Parallel, delayed\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "# Parallel(n_jobs=7)(delayed(match)(task) for task in tasks)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 EMOTION\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
      "1 GAMBLING\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/GAMBLING/IC1_high.nii.gz\n",
      "2 LANGUAGE\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/LANGUAGE/IC1_high.nii.gz\n",
      "3 MOTOR\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/MOTOR/IC1_high.nii.gz\n",
      "4 RELATIONAL\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/RELATIONAL/IC1_high.nii.gz\n",
      "5 SOCIAL\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/SOCIAL/IC1_high.nii.gz\n",
      "6 WM\n",
      "/home/share/TmpData/Qinglin/HCP_4mm_GLM/WM/IC1_high.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# best match of 7 tasks\n",
    "import operator\n",
    "import numpy as np\n",
    "from shutil import copyfile\n",
    "import shutil\n",
    "D1=[]        \n",
    "cope=[0,1,1,1,4,1,1]\n",
    "def match(i,task):\n",
    "    map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "\n",
    "    maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "    maps_GLM=maps_GLM\n",
    "        \n",
    "    D=LayerOverlap(maps_GLM,map1)\n",
    "    D1.append(D[cope[i]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i,task in enumerate(tasks):\n",
    "    print(i, task)\n",
    "    match(i,task)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "def plot(D,file):\n",
    "    plt.figure(figsize=(15,3))\n",
    "    plt.ylim(1, 7)\n",
    "    plt.xlim(1, 101)\n",
    "#     plt.xlabel(1,100)\n",
    "    sns_plot=sns.heatmap(D,cmap=\"Reds\",vmax=1,xticklabels=5, yticklabels=1)\n",
    "    plt.savefig(file, bbox_inches='tight')\n",
    "  \n",
    "plot(D1,'/home/uga_qinglin/Documents/All_D1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-5e547fb9f471>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "D1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "15003\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(np.count_nonzero(a))\n",
    "Jupyter Notebook\n",
    "3.GLM Last Checkpoint: 12/08/2018 (autosaved) Current Kernel Logo \n",
    "\n",
    "Python 3\n",
    "\n",
    "    File\n",
    "    Edit\n",
    "    View\n",
    "    Insert\n",
    "    Cell\n",
    "    Kernel\n",
    "    Widgets\n",
    "    Help\n",
    "\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "\n",
    "from nilearn import image\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "​\n",
    "\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "masker = NiftiMasker(mask_img=mask_img,standardize=True)\n",
    "\n",
    "masker.fit()\n",
    "\n",
    "​\n",
    "\n",
    "def flip(row):\n",
    "\n",
    "    if np.sum(row > 0) < np.sum(row < 0):\n",
    "\n",
    "        row *= -1\n",
    "\n",
    "        \n",
    "\n",
    "def load_maps(file):\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    GLM=image.load_img(file)\n",
    "\n",
    "    maps_GLM=masker.transform(GLM)\n",
    "\n",
    "#     for row in maps_GLM:\n",
    "\n",
    "#         flip(row)\n",
    "\n",
    "    maps_GLM[maps_GLM<0]=0\n",
    "\n",
    "    return maps_GLM\n",
    "\n",
    "​\n",
    "\n",
    "# plot GLM map\n",
    "\n",
    "from nilearn.image import iter_img\n",
    "\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "from pylab import figure\n",
    "\n",
    "import os\n",
    "\n",
    "​\n",
    "\n",
    "def save_maps(components_img,dir):        \n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    \n",
    "\n",
    "    for i, cur_img in enumerate(iter_img(components_img)):\n",
    "\n",
    "        outname=dir+str(i)+'.png'\n",
    "\n",
    "        plot_stat_map(cur_img, display_mode=\"z\", black_bg=True,cut_coords=10,\n",
    "\n",
    "                     colorbar=True,output_file=outname,title=\"Cope %d\" % int(i+1))\n",
    "\n",
    "​\n",
    "\n",
    "tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    file='/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz'\n",
    "\n",
    "    maps_GLM=load_maps(file)\n",
    "\n",
    "    maps_GLM = masker.inverse_transform(maps_GLM)\n",
    "\n",
    "    dir='/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_GLM/'\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    save_maps(maps_GLM,dir)        \n",
    "\n",
    " \n",
    "\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/GAMBLING/IC1_high.nii.gz\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyboardInterrupt                         Traceback (most recent call last)\n",
    "<ipython-input-170-8596760115fa> in <module>\n",
    "     45     if not os.path.exists(dir):\n",
    "     46         os.makedirs(dir)\n",
    "---> 47     save_maps(maps_GLM,dir)\n",
    "     48 \n",
    "\n",
    "<ipython-input-170-8596760115fa> in save_maps(components_img, dir)\n",
    "     35         outname=dir+str(i)+'.png'\n",
    "     36         plot_stat_map(cur_img, display_mode=\"z\", black_bg=True,cut_coords=10,\n",
    "---> 37                      colorbar=True,output_file=outname,title=\"Cope %d\" % int(i+1))\n",
    "     38 \n",
    "     39 tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in plot_stat_map(stat_map_img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, cmap, symmetric_cbar, dim, vmax, resampling_interpolation, **kwargs)\n",
    "   1030         bg_vmin=bg_vmin, bg_vmax=bg_vmax, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "   1031         colorbar=colorbar, cbar_vmin=cbar_vmin, cbar_vmax=cbar_vmax,\n",
    "-> 1032         resampling_interpolation=resampling_interpolation, **kwargs)\n",
    "   1033 \n",
    "   1034     return display\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in _plot_img_with_bg(img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, vmin, vmax, bg_vmin, bg_vmax, interpolation, display_factory, cbar_vmin, cbar_vmax, brain_color, **kwargs)\n",
    "    180         display.add_overlay(bg_img,\n",
    "    181                             vmin=bg_vmin, vmax=bg_vmax,\n",
    "--> 182                             cmap=plt.cm.gray, interpolation=interpolation)\n",
    "    183 \n",
    "    184     if img is not None and img is not False:\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/displays.py in add_overlay(self, img, threshold, colorbar, **kwargs)\n",
    "    681         # with plot_stat_map\n",
    "    682         kwargs.setdefault('interpolation', 'nearest')\n",
    "--> 683         ims = self._map_show(img, type='imshow', threshold=threshold, **kwargs)\n",
    "    684 \n",
    "    685         # `ims` can be empty in some corner cases, look at test_img_plotting.test_outlier_cut_coords.\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/displays.py in _map_show(self, img, type, resampling_interpolation, threshold, **kwargs)\n",
    "    765             not_mask = np.logical_not(data.mask)\n",
    "    766             xmin_, xmax_, ymin_, ymax_, zmin_, zmax_ = \\\n",
    "--> 767                 get_mask_bounds(new_img_like(img, not_mask, affine))\n",
    "    768 \n",
    "    769         data_2d_list = []\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/image/resampling.py in get_mask_bounds(img)\n",
    "    206 \n",
    "    207     \"\"\"\n",
    "--> 208     img = _utils.check_niimg_3d(img)\n",
    "    209     mask = _utils.numpy_conversions._asarray(img.get_data(), dtype=np.bool)\n",
    "    210     affine = img.affine\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg_conversions.py in check_niimg_3d(niimg, dtype)\n",
    "    320     Its application is idempotent.\n",
    "    321     \"\"\"\n",
    "--> 322     return check_niimg(niimg, ensure_ndim=3, dtype=dtype)\n",
    "    323 \n",
    "    324 \n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg_conversions.py in check_niimg(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\n",
    "    269 \n",
    "    270     # Otherwise, it should be a filename or a SpatialImage, we load it\n",
    "--> 271     niimg = load_niimg(niimg, dtype=dtype)\n",
    "    272 \n",
    "    273     if ensure_ndim == 3 and len(niimg.shape) == 4 and niimg.shape[3] == 1:\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg.py in load_niimg(niimg, dtype)\n",
    "    114                         + short_repr(niimg))\n",
    "    115 \n",
    "--> 116     dtype = _get_target_dtype(niimg.get_data().dtype, dtype)\n",
    "    117 \n",
    "    118     if dtype is not None:\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in get_data(self)\n",
    "    333 \n",
    "    334     def get_data(self):\n",
    "--> 335         self.load()\n",
    "    336         return self.data\n",
    "    337 \n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in load(self)\n",
    "    325             data = anat_img.get_data()\n",
    "    326             data = data.astype(np.float)\n",
    "--> 327             anat_mask = ndimage.morphology.binary_fill_holes(data > 0)\n",
    "    328             data = np.ma.masked_array(data, np.logical_not(anat_mask))\n",
    "    329             self._affine = anat_img.affine\n",
    "\n",
    "KeyboardInterrupt: \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def MapOverlap( a, b):\n",
    "\n",
    "    Intersect = np.logical_and(a, b)\n",
    "\n",
    "    Union=np.logical_or(a, b)\n",
    "\n",
    "    return np.count_nonzero(Intersect)/np.count_nonzero(Union)\n",
    "\n",
    "def MapOverlap2( GLM, b):\n",
    "\n",
    "    Intersect = np.logical_and(GLM, b)\n",
    "\n",
    "    Union=np.logical_or(GLM, b)\n",
    "\n",
    "    if np.count_nonzero(Union)   ==0:\n",
    "\n",
    "        U=0\n",
    "\n",
    "    else:\n",
    "\n",
    "        U=np.count_nonzero(GLM)/np.count_nonzero(Union)   \n",
    "\n",
    "    return np.count_nonzero(Intersect)/np.count_nonzero(GLM)-U\n",
    "\n",
    "def MapHierach( a, b):\n",
    "\n",
    "    I = np.count_nonzero(np.logical_and(a, b))\n",
    "\n",
    "    A=np.count_nonzero(a)\n",
    "\n",
    "    B=np.count_nonzero(b)\n",
    "\n",
    "    return I/min([A,B])\n",
    "\n",
    "def Euclid(a,b):\n",
    "\n",
    "    a = np.where(a > 10e-6, 1, 0)\n",
    "\n",
    "    b = np.where(b > 10e-6, 1, 0)\n",
    "\n",
    "    np.count_nonzero(a-b)\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def KL(a,b):\n",
    "\n",
    "    return (entropy(a,b)+entropy(b,a))/2\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def LayerOverlap(A,B):\n",
    "\n",
    "    D=[]\n",
    "\n",
    "    for i,a in enumerate(A):\n",
    "\n",
    "        D.append([])\n",
    "\n",
    "        \n",
    "\n",
    "        for j,b in enumerate(B):\n",
    "\n",
    "#             score=metrics.mutual_info_score(a,b)\n",
    "\n",
    "            score=MapHierach(a,b)\n",
    "\n",
    "#             score=KL(a,b)\n",
    "\n",
    "#             score = Euclid(a,b)\n",
    "\n",
    "            D[i].append(score)\n",
    "\n",
    "    return D\n",
    "\n",
    "# # plot all Overlap\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# def plot(D,file):\n",
    "\n",
    "#     plt.ylim(1, 7)\n",
    "\n",
    "#     plt.figure(figsize=(5,2))\n",
    "\n",
    "#     sns_plot=sns.heatmap(D,cmap=\"Reds\",vmax=1)\n",
    "\n",
    "#     plt.savefig(file, bbox_inches='tight')\n",
    "\n",
    "  \n",
    "\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "# def run(task):\n",
    "\n",
    "#     map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "\n",
    "#     map2=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map2.npy')\n",
    "\n",
    "#     map3=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map3.npy')\n",
    "\n",
    "#     maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "\n",
    "#     D1=LayerOverlap(maps_GLM,map1)\n",
    "\n",
    "#     D2=LayerOverlap(maps_GLM,map2)\n",
    "\n",
    "#     D3=LayerOverlap(maps_GLM,map3)\n",
    "\n",
    "#     plot(D1,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D1.png')\n",
    "\n",
    "#     plot(D2,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D2.png')\n",
    "\n",
    "#     plot(D3,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D3.png')\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "# Parallel(n_jobs=7)(delayed(run)(task) for task in tasks)\n",
    "\n",
    "​\n",
    "\n",
    "  \n",
    "\n",
    "​\n",
    "\n",
    "# best match of 7 tasks\n",
    "\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "def match(task):\n",
    "\n",
    "    map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "\n",
    "    map2=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map2.npy')\n",
    "\n",
    "    map3=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map3.npy')\n",
    "\n",
    "    maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "\n",
    "​\n",
    "\n",
    "    D1=LayerOverlap(maps_GLM,map1)\n",
    "\n",
    "    D2=LayerOverlap(maps_GLM,map2)\n",
    "\n",
    "    D3=LayerOverlap(maps_GLM,map3)\n",
    "\n",
    "​\n",
    "\n",
    "    src='/home/share/TmpData/Qinglin/HCP_Group_DBN/Maps_ortho/'\n",
    "\n",
    "    dst='/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_match/'\n",
    "\n",
    "    shutil.rmtree(dst) \n",
    "\n",
    "    if not os.path.exists(dst):\n",
    "\n",
    "            os.makedirs(dst)\n",
    "\n",
    "    \n",
    "\n",
    "    copyfile('/home/share/TmpData/Qinglin/HCP_4mm/100206/MNINonLinear/Results/tfMRI_'+task+'_LR/tfMRI_'+task+'_LR_hp200_s4.feat/design.png', dst+'design.png')\n",
    "\n",
    "    for t in list(range(0,len(maps_GLM))):\n",
    "\n",
    "#     for t in list(range(0,6)):\n",
    "\n",
    "        index1, value = max(enumerate(D1[t]), key=operator.itemgetter(1))\n",
    "\n",
    "        index2, value = max(enumerate(D2[t]), key=operator.itemgetter(1))\n",
    "\n",
    "        index3, value = max(enumerate(D3[t]), key=operator.itemgetter(1))\n",
    "\n",
    "        print(index1,index2,index3)        \n",
    "\n",
    "        copyfile(src+task+'_W1/'+str(index1+1)+'.png', dst+str(t)+'_W1_'+str(index1+1)+'.png')\n",
    "\n",
    "        copyfile(src+task+'_W2/'+str(index2+1)+'.png', dst+str(t)+'_W2_'+str(index1+1)+'.png')\n",
    "\n",
    "        copyfile(src+task+'_W3/'+str(index3+1)+'.png', dst+str(t)+'_W3_'+str(index1+1)+'.png')\n",
    "\n",
    "        \n",
    "\n",
    "        copyfile('/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/EMOTION_GLM/'+str(t)+'.png', dst+str(t)+'.png')\n",
    "\n",
    "        \n",
    "\n",
    "match('EMOTION')        \n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "# Parallel(n_jobs=7)(delayed(match)(task) for task in tasks)        \n",
    "\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
    "88 18 71\n",
    "88 88 8\n",
    "88 54 71\n",
    "88 80 89\n",
    "88 76 89\n",
    "88 88 89\n",
    "\n",
    "# best match of 7 tasks\n",
    "\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "D1=[]        \n",
    "\n",
    "cope=[0,1,1,1,4,1,1]\n",
    "\n",
    "def match(i,task):\n",
    "\n",
    "    map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "\n",
    "​\n",
    "\n",
    "    maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "\n",
    "    maps_GLM=maps_GLM\n",
    "\n",
    "        \n",
    "\n",
    "    D=LayerOverlap(maps_GLM,map1)\n",
    "\n",
    "    D1.append(D[cope[i]])\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "for i,task in enumerate(tasks):\n",
    "\n",
    "    print(i, task)\n",
    "\n",
    "    match(i,task)\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "    \n",
    "\n",
    "0 EMOTION\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
    "1 GAMBLING\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/GAMBLING/IC1_high.nii.gz\n",
    "2 LANGUAGE\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/LANGUAGE/IC1_high.nii.gz\n",
    "3 MOTOR\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/MOTOR/IC1_high.nii.gz\n",
    "4 RELATIONAL\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/RELATIONAL/IC1_high.nii.gz\n",
    "5 SOCIAL\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/SOCIAL/IC1_high.nii.gz\n",
    "6 WM\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/WM/IC1_high.nii.gz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def plot(D,file):\n",
    "\n",
    "    plt.figure(figsize=(15,3))\n",
    "\n",
    "    plt.ylim(1, 7)\n",
    "\n",
    "    plt.xlim(1, 101)\n",
    "\n",
    "#     plt.xlabel(1,100)\n",
    "\n",
    "    sns_plot=sns.heatmap(D,cmap=\"Reds\",vmax=1,xticklabels=5, yticklabels=1)\n",
    "\n",
    "    plt.savefig(file, bbox_inches='tight')\n",
    "\n",
    "  \n",
    "\n",
    "plot(D1,'/home/uga_qinglin/Documents/All_D1.png')\n",
    "\n",
    "D1[1].shape\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "<ipython-input-180-5e547fb9f471> in <module>\n",
    "----> 1 D1[1].shape\n",
    "\n",
    "AttributeError: 'list' object has no attribute 'shape'\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(np.count_nonzero(a))\n",
    "\n",
    "Jupyter Notebook\n",
    "3.GLM Last Checkpoint: 12/08/2018 (autosaved) Current Kernel Logo \n",
    "\n",
    "Python 3\n",
    "\n",
    "    File\n",
    "    Edit\n",
    "    View\n",
    "    Insert\n",
    "    Cell\n",
    "    Kernel\n",
    "    Widgets\n",
    "    Help\n",
    "\n",
    "from nilearn.datasets import load_mni152_brain_mask\n",
    "\n",
    "from nilearn import image\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "\n",
    "​\n",
    "\n",
    "mask_img = load_mni152_brain_mask()\n",
    "\n",
    "masker = NiftiMasker(mask_img=mask_img,standardize=True)\n",
    "\n",
    "masker.fit()\n",
    "\n",
    "​\n",
    "\n",
    "def flip(row):\n",
    "\n",
    "    if np.sum(row > 0) < np.sum(row < 0):\n",
    "\n",
    "        row *= -1\n",
    "\n",
    "        \n",
    "\n",
    "def load_maps(file):\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    GLM=image.load_img(file)\n",
    "\n",
    "    maps_GLM=masker.transform(GLM)\n",
    "\n",
    "#     for row in maps_GLM:\n",
    "\n",
    "#         flip(row)\n",
    "\n",
    "    maps_GLM[maps_GLM<0]=0\n",
    "\n",
    "    return maps_GLM\n",
    "\n",
    "​\n",
    "\n",
    "# plot GLM map\n",
    "\n",
    "from nilearn.image import iter_img\n",
    "\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "from pylab import figure\n",
    "\n",
    "import os\n",
    "\n",
    "​\n",
    "\n",
    "def save_maps(components_img,dir):        \n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    \n",
    "\n",
    "    for i, cur_img in enumerate(iter_img(components_img)):\n",
    "\n",
    "        outname=dir+str(i)+'.png'\n",
    "\n",
    "        plot_stat_map(cur_img, display_mode=\"z\", black_bg=True,cut_coords=10,\n",
    "\n",
    "                     colorbar=True,output_file=outname,title=\"Cope %d\" % int(i+1))\n",
    "\n",
    "​\n",
    "\n",
    "tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "for task in tasks:\n",
    "\n",
    "    file='/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz'\n",
    "\n",
    "    maps_GLM=load_maps(file)\n",
    "\n",
    "    maps_GLM = masker.inverse_transform(maps_GLM)\n",
    "\n",
    "    dir='/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_GLM/'\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    save_maps(maps_GLM,dir)        \n",
    "\n",
    " \n",
    "\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/GAMBLING/IC1_high.nii.gz\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "KeyboardInterrupt                         Traceback (most recent call last)\n",
    "<ipython-input-170-8596760115fa> in <module>\n",
    "     45     if not os.path.exists(dir):\n",
    "     46         os.makedirs(dir)\n",
    "---> 47     save_maps(maps_GLM,dir)\n",
    "     48 \n",
    "\n",
    "<ipython-input-170-8596760115fa> in save_maps(components_img, dir)\n",
    "     35         outname=dir+str(i)+'.png'\n",
    "     36         plot_stat_map(cur_img, display_mode=\"z\", black_bg=True,cut_coords=10,\n",
    "---> 37                      colorbar=True,output_file=outname,title=\"Cope %d\" % int(i+1))\n",
    "     38 \n",
    "     39 tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in plot_stat_map(stat_map_img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, cmap, symmetric_cbar, dim, vmax, resampling_interpolation, **kwargs)\n",
    "   1030         bg_vmin=bg_vmin, bg_vmax=bg_vmax, cmap=cmap, vmin=vmin, vmax=vmax,\n",
    "   1031         colorbar=colorbar, cbar_vmin=cbar_vmin, cbar_vmax=cbar_vmax,\n",
    "-> 1032         resampling_interpolation=resampling_interpolation, **kwargs)\n",
    "   1033 \n",
    "   1034     return display\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in _plot_img_with_bg(img, bg_img, cut_coords, output_file, display_mode, colorbar, figure, axes, title, threshold, annotate, draw_cross, black_bg, vmin, vmax, bg_vmin, bg_vmax, interpolation, display_factory, cbar_vmin, cbar_vmax, brain_color, **kwargs)\n",
    "    180         display.add_overlay(bg_img,\n",
    "    181                             vmin=bg_vmin, vmax=bg_vmax,\n",
    "--> 182                             cmap=plt.cm.gray, interpolation=interpolation)\n",
    "    183 \n",
    "    184     if img is not None and img is not False:\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/displays.py in add_overlay(self, img, threshold, colorbar, **kwargs)\n",
    "    681         # with plot_stat_map\n",
    "    682         kwargs.setdefault('interpolation', 'nearest')\n",
    "--> 683         ims = self._map_show(img, type='imshow', threshold=threshold, **kwargs)\n",
    "    684 \n",
    "    685         # `ims` can be empty in some corner cases, look at test_img_plotting.test_outlier_cut_coords.\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/displays.py in _map_show(self, img, type, resampling_interpolation, threshold, **kwargs)\n",
    "    765             not_mask = np.logical_not(data.mask)\n",
    "    766             xmin_, xmax_, ymin_, ymax_, zmin_, zmax_ = \\\n",
    "--> 767                 get_mask_bounds(new_img_like(img, not_mask, affine))\n",
    "    768 \n",
    "    769         data_2d_list = []\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/image/resampling.py in get_mask_bounds(img)\n",
    "    206 \n",
    "    207     \"\"\"\n",
    "--> 208     img = _utils.check_niimg_3d(img)\n",
    "    209     mask = _utils.numpy_conversions._asarray(img.get_data(), dtype=np.bool)\n",
    "    210     affine = img.affine\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg_conversions.py in check_niimg_3d(niimg, dtype)\n",
    "    320     Its application is idempotent.\n",
    "    321     \"\"\"\n",
    "--> 322     return check_niimg(niimg, ensure_ndim=3, dtype=dtype)\n",
    "    323 \n",
    "    324 \n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg_conversions.py in check_niimg(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\n",
    "    269 \n",
    "    270     # Otherwise, it should be a filename or a SpatialImage, we load it\n",
    "--> 271     niimg = load_niimg(niimg, dtype=dtype)\n",
    "    272 \n",
    "    273     if ensure_ndim == 3 and len(niimg.shape) == 4 and niimg.shape[3] == 1:\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/niimg.py in load_niimg(niimg, dtype)\n",
    "    114                         + short_repr(niimg))\n",
    "    115 \n",
    "--> 116     dtype = _get_target_dtype(niimg.get_data().dtype, dtype)\n",
    "    117 \n",
    "    118     if dtype is not None:\n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in get_data(self)\n",
    "    333 \n",
    "    334     def get_data(self):\n",
    "--> 335         self.load()\n",
    "    336         return self.data\n",
    "    337 \n",
    "\n",
    "/usr/local/lib/python3.5/dist-packages/nilearn/plotting/img_plotting.py in load(self)\n",
    "    325             data = anat_img.get_data()\n",
    "    326             data = data.astype(np.float)\n",
    "--> 327             anat_mask = ndimage.morphology.binary_fill_holes(data > 0)\n",
    "    328             data = np.ma.masked_array(data, np.logical_not(anat_mask))\n",
    "    329             self._affine = anat_img.affine\n",
    "\n",
    "KeyboardInterrupt: \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def MapOverlap( a, b):\n",
    "\n",
    "    Intersect = np.logical_and(a, b)\n",
    "\n",
    "    Union=np.logical_or(a, b)\n",
    "\n",
    "    return np.count_nonzero(Intersect)/np.count_nonzero(Union)\n",
    "\n",
    "def MapOverlap2( GLM, b):\n",
    "\n",
    "    Intersect = np.logical_and(GLM, b)\n",
    "\n",
    "    Union=np.logical_or(GLM, b)\n",
    "\n",
    "    if np.count_nonzero(Union)   ==0:\n",
    "\n",
    "        U=0\n",
    "\n",
    "    else:\n",
    "\n",
    "        U=np.count_nonzero(GLM)/np.count_nonzero(Union)   \n",
    "\n",
    "    return np.count_nonzero(Intersect)/np.count_nonzero(GLM)-U\n",
    "\n",
    "def MapHierach( a, b):\n",
    "\n",
    "    I = np.count_nonzero(np.logical_and(a, b))\n",
    "\n",
    "    A=np.count_nonzero(a)\n",
    "\n",
    "    B=np.count_nonzero(b)\n",
    "\n",
    "    return I/min([A,B])\n",
    "\n",
    "def Euclid(a,b):\n",
    "\n",
    "    a = np.where(a > 10e-6, 1, 0)\n",
    "\n",
    "    b = np.where(b > 10e-6, 1, 0)\n",
    "\n",
    "    np.count_nonzero(a-b)\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def KL(a,b):\n",
    "\n",
    "    return (entropy(a,b)+entropy(b,a))/2\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "def LayerOverlap(A,B):\n",
    "\n",
    "    D=[]\n",
    "\n",
    "    for i,a in enumerate(A):\n",
    "\n",
    "        D.append([])\n",
    "\n",
    "        \n",
    "\n",
    "        for j,b in enumerate(B):\n",
    "\n",
    "#             score=metrics.mutual_info_score(a,b)\n",
    "\n",
    "            score=MapHierach(a,b)\n",
    "\n",
    "#             score=KL(a,b)\n",
    "\n",
    "#             score = Euclid(a,b)\n",
    "\n",
    "            D[i].append(score)\n",
    "\n",
    "    return D\n",
    "\n",
    "# # plot all Overlap\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "# def plot(D,file):\n",
    "\n",
    "#     plt.ylim(1, 7)\n",
    "\n",
    "#     plt.figure(figsize=(5,2))\n",
    "\n",
    "#     sns_plot=sns.heatmap(D,cmap=\"Reds\",vmax=1)\n",
    "\n",
    "#     plt.savefig(file, bbox_inches='tight')\n",
    "\n",
    "  \n",
    "\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "# def run(task):\n",
    "\n",
    "#     map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "\n",
    "#     map2=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map2.npy')\n",
    "\n",
    "#     map3=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map3.npy')\n",
    "\n",
    "#     maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "\n",
    "#     D1=LayerOverlap(maps_GLM,map1)\n",
    "\n",
    "#     D2=LayerOverlap(maps_GLM,map2)\n",
    "\n",
    "#     D3=LayerOverlap(maps_GLM,map3)\n",
    "\n",
    "#     plot(D1,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D1.png')\n",
    "\n",
    "#     plot(D2,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D2.png')\n",
    "\n",
    "#     plot(D3,'/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_D3.png')\n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "# Parallel(n_jobs=7)(delayed(run)(task) for task in tasks)\n",
    "\n",
    "​\n",
    "\n",
    "  \n",
    "\n",
    "​\n",
    "\n",
    "# best match of 7 tasks\n",
    "\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "def match(task):\n",
    "\n",
    "    map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "\n",
    "    map2=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map2.npy')\n",
    "\n",
    "    map3=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map3.npy')\n",
    "\n",
    "    maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "\n",
    "​\n",
    "\n",
    "    D1=LayerOverlap(maps_GLM,map1)\n",
    "\n",
    "    D2=LayerOverlap(maps_GLM,map2)\n",
    "\n",
    "    D3=LayerOverlap(maps_GLM,map3)\n",
    "\n",
    "​\n",
    "\n",
    "    src='/home/share/TmpData/Qinglin/HCP_Group_DBN/Maps_ortho/'\n",
    "\n",
    "    dst='/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/'+task+'_match/'\n",
    "\n",
    "    shutil.rmtree(dst) \n",
    "\n",
    "    if not os.path.exists(dst):\n",
    "\n",
    "            os.makedirs(dst)\n",
    "\n",
    "    \n",
    "\n",
    "    copyfile('/home/share/TmpData/Qinglin/HCP_4mm/100206/MNINonLinear/Results/tfMRI_'+task+'_LR/tfMRI_'+task+'_LR_hp200_s4.feat/design.png', dst+'design.png')\n",
    "\n",
    "    for t in list(range(0,len(maps_GLM))):\n",
    "\n",
    "#     for t in list(range(0,6)):\n",
    "\n",
    "        index1, value = max(enumerate(D1[t]), key=operator.itemgetter(1))\n",
    "\n",
    "        index2, value = max(enumerate(D2[t]), key=operator.itemgetter(1))\n",
    "\n",
    "        index3, value = max(enumerate(D3[t]), key=operator.itemgetter(1))\n",
    "\n",
    "        print(index1,index2,index3)        \n",
    "\n",
    "        copyfile(src+task+'_W1/'+str(index1+1)+'.png', dst+str(t)+'_W1_'+str(index1+1)+'.png')\n",
    "\n",
    "        copyfile(src+task+'_W2/'+str(index2+1)+'.png', dst+str(t)+'_W2_'+str(index1+1)+'.png')\n",
    "\n",
    "        copyfile(src+task+'_W3/'+str(index3+1)+'.png', dst+str(t)+'_W3_'+str(index1+1)+'.png')\n",
    "\n",
    "        \n",
    "\n",
    "        copyfile('/home/share/TmpData/Qinglin/HCP_Group_DBN/GLM/EMOTION_GLM/'+str(t)+'.png', dst+str(t)+'.png')\n",
    "\n",
    "        \n",
    "\n",
    "match('EMOTION')        \n",
    "\n",
    "# from joblib import Parallel, delayed\n",
    "\n",
    "# tasks=['EMOTION','GAMBLING','LANGUAGE','MOTOR','RELATIONAL','SOCIAL','WM']\n",
    "\n",
    "# Parallel(n_jobs=7)(delayed(match)(task) for task in tasks)        \n",
    "\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
    "88 18 71\n",
    "88 88 8\n",
    "88 54 71\n",
    "88 80 89\n",
    "88 76 89\n",
    "88 88 89\n",
    "\n",
    "# best match of 7 tasks\n",
    "\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from shutil import copyfile\n",
    "\n",
    "import shutil\n",
    "\n",
    "D1=[]        \n",
    "\n",
    "cope=[0,1,1,1,4,1,1]\n",
    "\n",
    "def match(i,task):\n",
    "\n",
    "    map1=np.load('/home/share/TmpData/Qinglin/HCP_Group_DBN/'+task+'_map1.npy')\n",
    "\n",
    "​\n",
    "\n",
    "    maps_GLM=load_maps('/home/share/TmpData/Qinglin/HCP_4mm_GLM/'+task+'/IC1_high.nii.gz')\n",
    "\n",
    "    maps_GLM=maps_GLM\n",
    "\n",
    "        \n",
    "\n",
    "    D=LayerOverlap(maps_GLM,map1)\n",
    "\n",
    "    D1.append(D[cope[i]])\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "for i,task in enumerate(tasks):\n",
    "\n",
    "    print(i, task)\n",
    "\n",
    "    match(i,task)\n",
    "\n",
    "​\n",
    "\n",
    "​\n",
    "\n",
    "    \n",
    "\n",
    "0 EMOTION\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/EMOTION/IC1_high.nii.gz\n",
    "1 GAMBLING\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/GAMBLING/IC1_high.nii.gz\n",
    "2 LANGUAGE\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/LANGUAGE/IC1_high.nii.gz\n",
    "3 MOTOR\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/MOTOR/IC1_high.nii.gz\n",
    "4 RELATIONAL\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/RELATIONAL/IC1_high.nii.gz\n",
    "5 SOCIAL\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/SOCIAL/IC1_high.nii.gz\n",
    "6 WM\n",
    "/home/share/TmpData/Qinglin/HCP_4mm_GLM/WM/IC1_high.nii.gz\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def plot(D,file):\n",
    "\n",
    "    plt.figure(figsize=(15,3))\n",
    "\n",
    "    plt.ylim(1, 7)\n",
    "\n",
    "    plt.xlim(1, 101)\n",
    "\n",
    "#     plt.xlabel(1,100)\n",
    "\n",
    "    sns_plot=sns.heatmap(D,cmap=\"Reds\",vmax=1,xticklabels=5, yticklabels=1)\n",
    "\n",
    "    plt.savefig(file, bbox_inches='tight')\n",
    "\n",
    "  \n",
    "\n",
    "plot(D1,'/home/uga_qinglin/Documents/All_D1.png')\n",
    "\n",
    "D1[1].shape\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "<ipython-input-180-5e547fb9f471> in <module>\n",
    "----> 1 D1[1].shape\n",
    "\n",
    "AttributeError: 'list' object has no attribute 'shape'\n",
    "\n",
    "print(a)\n",
    "\n",
    "print(np.count_nonzero(a))\n",
    "\n",
    "[0 0 0 ... 0 0 0]\n",
    "15003\n",
    "\n",
    "b=map1[2]\n",
    "\n",
    "c=a-b\n",
    "\n",
    "print(np.count_nonzero(b))\n",
    "\n",
    "print(np.count_nonzero(c))\n",
    "\n",
    "1150\n",
    "16135\n",
    "\n",
    "​\n",
    "\n",
    "\n",
    "[0 0 0 ... 0 0 0]\n",
    "15003\n",
    "\n",
    "b=map1[2]\n",
    "\n",
    "c=a-b\n",
    "\n",
    "print(np.count_nonzero(b))\n",
    "\n",
    "print(np.count_nonzero(c))\n",
    "\n",
    "1150\n",
    "16135\n",
    "\n",
    "​\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=map1[2]\n",
    "c=a-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150\n",
      "16135\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(b))\n",
    "print(np.count_nonzero(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
