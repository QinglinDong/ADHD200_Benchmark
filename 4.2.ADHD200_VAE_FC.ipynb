{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train=np.load('/storage/ADHD200/athena/NYU/All_Data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 28546)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 256)          7308032     input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          32896       dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 64)           8256        dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 32)           2080        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 32)           2080        dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 32)           0           dense_31[0][0]                   \n",
      "                                                                 dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 64)           2112        lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 128)          8320        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 256)          33024       dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 28546)        7336322     dense_35[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 14,733,122\n",
      "Trainable params: 14,733,122\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "37152/37152 [==============================] - 371s 10ms/step - loss: -2923.1441\n",
      "Epoch 2/10\n",
      " 9257/37152 [======>.......................] - ETA: 4:39 - loss: -5147.0918"
     ]
    }
   ],
   "source": [
    "'''This script demonstrates how to build a variational autoencoder with Keras.\n",
    "\n",
    " #Reference\n",
    "\n",
    " - Auto-Encoding Variational Bayes\n",
    "   https://arxiv.org/abs/1312.6114\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from keras.datasets import mnist\n",
    "\n",
    "batch_size = 1\n",
    "original_dim=x_train.shape[1]\n",
    "latent_dim = 32\n",
    "intermediate_dim = 500\n",
    "epochs = 10\n",
    "epsilon_std = 1.0\n",
    "\n",
    "\n",
    "x = Input(shape=(original_dim,))\n",
    "h = Dense(256, activation='tanh')(x)\n",
    "h = Dense(128, activation='tanh')(h)\n",
    "h = Dense(64, activation='tanh')(h)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_var = Dense(latent_dim)(h)\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "# we instantiate these layers separately so as to reuse them later\n",
    "\n",
    "h_decoded = Dense(64, activation='tanh')(z)\n",
    "h_decoded = Dense(128, activation='tanh')(h_decoded)\n",
    "h_decoded = Dense(256, activation='tanh')(h_decoded)\n",
    "x_decoded_mean = Dense(original_dim, activation='sigmoid')(h_decoded)\n",
    "\n",
    "# instantiate VAE model\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# Compute VAE loss\n",
    "xent_loss = original_dim * metrics.binary_crossentropy(x,x_decoded_mean )\n",
    "kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "vae_loss = K.mean(xent_loss + kl_loss)\n",
    "\n",
    "vae.add_loss(vae_loss)\n",
    "from keras import optimizers\n",
    "rmsprop=optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.001)\n",
    "vae.compile(optimizer=rmsprop)\n",
    "vae.summary()\n",
    "\n",
    "\n",
    "vae.fit(x_train,\n",
    "        shuffle=True,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "encoder = Model(x, z_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder=Model(x, z)\n",
    "y=decoder.predict(x_train,\n",
    "        batch_size=batch_size)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "t = range(0, 200)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(t, y[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "clf = Lasso(alpha=0.1)\n",
    "clf.fit(y,x_train)\n",
    "print(clf.coef_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#W=decoder_mean.get_weights()\n",
    "#components_img=W[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=canica.masker_.mask_img_, standardize=True)\n",
    "masker.fit()\n",
    "\n",
    "import numpy as np\n",
    "components_img = masker.inverse_transform(np.transpose(clf.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "\n",
    "plotting.plot_prob_atlas(components_img, view_type='filled_contours',\n",
    "                         title='All RBM components')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for i, cur_img in enumerate(iter_img(components_img)):\n",
    "    plot_stat_map(cur_img, display_mode=\"ortho\", title=\"IC %d\" % i,\n",
    "                  cut_coords=None, colorbar='bwr')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
