{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dictionary Learning and ICA for doing group analysis of resting-state fMRI\n",
    "==========================================================================\n",
    "\n",
    "This example applies dictionary learning and ICA to resting-state data,\n",
    "visualizing resulting components using atlas plotting tools.\n",
    "\n",
    "Dictionary learning is a sparsity based decomposition method for extracting\n",
    "spatial maps. It extracts maps that are naturally sparse and usually cleaner\n",
    "than ICA\n",
    "\n",
    "   * Arthur Mensch et al. `Compressed online dictionary learning for fast resting-state fMRI decomposition\n",
    "     <https://hal.archives-ouvertes.fr/hal-01271033/>`_,\n",
    "     ISBI 2016, Lecture Notes in Computer Science\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The use of the attribute `components_img_` from decomposition\n",
    "    estimators is implemented from version 0.4.1.\n",
    "    For older versions, unmask the deprecated attribute `components_` to\n",
    "    get the components image using attribute `masker_` embedded in estimator.\n",
    "    See the `section Inverse transform: unmasking data <unmasking_step>`.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ADHD rest dataset\n",
    "-----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First functional nifti image (4D) is at: /home/share/TmpData/Qinglin/nilearn_data/adhd/data/0010042/0010042_rest_tshift_RPI_voreg_mni.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/nilearn/datasets/func.py:503: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "  dtype=None)\n"
     ]
    }
   ],
   "source": [
    "from nilearn import datasets\n",
    "\n",
    "adhd_dataset = datasets.fetch_adhd(n_subjects=30,data_dir='/home/share/TmpData/Qinglin/nilearn_data/')\n",
    "func_filenames = adhd_dataset.func  # list of 4D nifti files for each subject\n",
    "\n",
    "# print basic information on the dataset\n",
    "print('First functional nifti image (4D) is at: %s' %\n",
    "      adhd_dataset.func[0])  # 4D data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two decomposition estimators\n",
    "------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from nilearn.decomposition import DictLearning, CanICA\n",
    "\n",
    "n_components = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary learning\n",
    "--------------------\n",
    "\n",
    "We use as \"template\" as a strategy to compute the mask, as this leads\n",
    "to slightly faster and more reproducible results. However, the images\n",
    "need to be in MNI template space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_learning = DictLearning(n_components=n_components,\n",
    "                             memory=\"nilearn_cache\", memory_level=2,\n",
    "                             verbose=1,\n",
    "                             random_state=0,\n",
    "                             n_epochs=1,\n",
    "                             mask_strategy='template')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CanICA\n",
    "------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uga_qinglin/.local/lib/python3.5/site-packages/nibabel/nifti1.py:582: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  ext_def = np.fromstring(ext_def, dtype=np.int32)\n",
      "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/cache_mixin.py:232: DeprecationWarning: The 'cachedir' attribute has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "Use os.path.join(memory.location, 'joblib') attribute instead.\n",
      "  if (memory.cachedir is None and memory_level is not None\n",
      "/usr/local/lib/python3.5/dist-packages/nilearn/_utils/cache_mixin.py:309: UserWarning: Caching has been enabled (memory_level = 2) but no Memory object or path has been provided (parameter memory). Caching deactivated for function resample_img.\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from nilearn._utils.niimg_conversions import _resolve_globbing\n",
    "imgs = _resolve_globbing(func_filenames)\n",
    "\n",
    "from nilearn.masking import compute_epi_mask\n",
    "mask_img = compute_epi_mask(func_filenames)\n",
    "\n",
    "from nilearn.input_data import NiftiMasker\n",
    "masker = NiftiMasker(mask_img=mask_img, \n",
    "                     standardize=True,\n",
    "                     detrend=1,\n",
    "                     smoothing_fwhm=6., \n",
    "                     memory_level=2)\n",
    "fmri_masked = masker.fit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61, 73, 61)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_ExtractionFunctor' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/externals/loky/process_executor.py\", line 420, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 563, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 261, in __call__\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\", line 261, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/dist-packages/nilearn/decomposition/base.py\", line 206, in _mask_and_reduce_single\n    this_data = masker.transform(img, confound)\n  File \"/usr/local/lib/python3.5/dist-packages/nilearn/input_data/base_masker.py\", line 177, in transform\n    return self.transform_single_imgs(imgs, confounds)\n  File \"/usr/local/lib/python3.5/dist-packages/nilearn/input_data/nifti_masker.py\", line 307, in transform_single_imgs\n    dtype=self.dtype\n  File \"/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/memory.py\", line 329, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/nilearn/input_data/nifti_masker.py\", line 55, in filter_and_mask\n    dtype=dtype)\n  File \"/usr/local/lib/python3.5/dist-packages/nilearn/input_data/base_masker.py\", line 100, in filter_and_extract\n    memory_level=memory_level)(imgs)\n  File \"/usr/local/lib/python3.5/dist-packages/nilearn/_utils/cache_mixin.py\", line 238, in cache\n    (memory_level, func.__name__),\nAttributeError: '_ExtractionFunctor' object has no attribute '__name__'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ad6ba896834d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"nilearn_cache\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     n_jobs=8)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/nilearn/decomposition/base.py\u001b[0m in \u001b[0;36mmask_and_reduce\u001b[0;34m(masker, imgs, confounds, reduction_ratio, n_components, random_state, memory_level, memory, n_jobs)\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mmemory_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         ) for img, confound in zip(imgs, confounds))\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     subject_n_samples = [subject_data.shape[0]\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 996\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    515\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_ExtractionFunctor' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "from nilearn.decomposition.base import mask_and_reduce\n",
    "\n",
    "data = mask_and_reduce(\n",
    "    masker, imgs, confounds=None,\n",
    "    reduction_ratio=0.1,\n",
    "    random_state=0,\n",
    "    memory=\"nilearn_cache\",\n",
    "    memory_level=1,\n",
    "    n_jobs=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit both estimators\n",
    "--------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dict_learning._raw_fit(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.image import iter_img\n",
    "from nilearn.plotting import plot_stat_map, show\n",
    "\n",
    "for i, cur_img in enumerate(iter_img(components_img)):\n",
    "    plot_stat_map(cur_img, display_mode=\"ortho\", title=\"IC %d\" % i,\n",
    "                  cut_coords=None, colorbar='bwr')\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results\n",
    "----------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.plotting import (plot_prob_atlas, find_xyz_cut_coords, show,\n",
    "                              plot_stat_map)\n",
    "from nilearn.image import index_img\n",
    "\n",
    "# Selecting specific maps to display: maps were manually chosen to be similar\n",
    "indices = {dict_learning: 25}\n",
    "# We select relevant cut coordinates for displaying\n",
    "cut_component = index_img(components_imgs[0], indices[dict_learning])\n",
    "cut_coords = find_xyz_cut_coords(cut_component)\n",
    "for estimator, components in zip(estimators, components_imgs):\n",
    "    # 4D plotting\n",
    "    plot_prob_atlas(components, view_type=\"filled_contours\",\n",
    "                    title=\"%s\" % names[estimator],\n",
    "                    cut_coords=cut_coords, colorbar=False)\n",
    "    # 3D plotting\n",
    "    plot_stat_map(index_img(components, indices[estimator]),\n",
    "                  title=\"%s\" % names[estimator],\n",
    "                  cut_coords=cut_coords, colorbar=False)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
